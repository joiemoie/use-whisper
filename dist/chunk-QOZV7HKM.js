import './chunk-VO7VPLVP.js';
import { useEffectAsync } from '@chengsokdara/react-hooks-async';
import { useRef, useState, useEffect } from 'react';

var G={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onDataAvailableTranscribe:void 0,onTranscribe:void 0},I={stop:void 0},J={blob:void 0,text:void 0},ce=R=>{let{apiKey:L,autoStart:g,autoTranscribe:w,mode:N,nonStop:T,removeSilence:Q,stopTimeout:v,streaming:d,timeSlice:C,whisperConfig:V,onDataAvailable:A,onDataAvailableTranscribe:X,onTranscribe:Y}={...G,...R},c=useRef([]),o=useRef(),n=useRef(),r=useRef(),t=useRef(),i=useRef(I),[U,p]=useState(!1),[W,S]=useState(!1),[D,Z]=useState(!1),[E,$]=useState(J);useEffect(()=>()=>{c.current&&(c.current=[]),o.current&&(o.current.flush(),o.current=void 0),r.current&&(r.current.destroy(),r.current=void 0),s("stop"),n.current&&(n.current.off("speaking",l),n.current.off("stopped_speaking",m)),t.current&&(t.current.getTracks().forEach(e=>e.stop()),t.current=void 0);},[]),useEffectAsync(async()=>{g&&await b();},[g]);let H=async()=>{await b();},x=async()=>{await O();},M=async()=>{await k();},P=async()=>{c.current=[];},b=async()=>{try{if(t.current||await _(),t.current){if(!r.current){let{default:{RecordRTCPromisesHandler:u,StereoAudioRecorder:j}}=await import('recordrtc'),q={mimeType:"audio/ogg",numberOfAudioChannels:1,recorderType:j,sampleRate:44100,timeSlice:d?C:void 0,type:"audio",ondataavailable:w&&d?K:void 0};r.current=new u(t.current,q);}if(!o.current){let{Mp3Encoder:u}=await import('lamejs');o.current=new u(1,44100,96);}let e=await r.current.getState();(e==="inactive"||e==="stopped")&&await r.current.startRecording(),e==="paused"&&await r.current.resumeRecording(),T&&h("stop"),p(!0);}}catch{}},_=async()=>{try{if(t.current&&t.current.getTracks().forEach(e=>e.stop()),t.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!n.current){let{default:e}=await import('hark');n.current=e(t.current,{interval:100,play:!1}),n.current.on("speaking",l),n.current.on("stopped_speaking",m);}}catch{}},h=e=>{i.current[e]||(i.current[e]=setTimeout(k,v));},l=()=>{S(!0),s("stop");},m=()=>{S(!1),T&&h("stop");},O=async()=>{try{r.current&&(await r.current.getState()==="recording"&&await r.current.pauseRecording(),s("stop"),p(!1));}catch{}},k=async()=>{try{if(r.current){let e=await r.current.getState();(e==="recording"||e==="paused")&&await r.current.stopRecording(),B(),s("stop"),p(!1),await r.current.destroy(),c.current=[],o.current&&(o.current.flush(),o.current=void 0),r.current=void 0;}}catch{}},B=()=>{n.current&&(n.current.off("speaking",l),n.current.off("stopped_speaking",m),n.current=void 0),t.current&&(t.current.getTracks().forEach(e=>e.stop()),t.current=void 0);},s=e=>{i.current[e]&&(clearTimeout(i.current[e]),i.current[e]=void 0);},K=async e=>{try{d&&r.current&&A?.(e);}catch{}};return {recording:U,speaking:W,transcribing:D,transcript:E,pauseRecording:x,startRecording:H,stopRecording:M,clearChunks:P}};

export { ce as a };
