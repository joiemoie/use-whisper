import { d, b, c } from './chunk-VO7VPLVP.js';
import { useEffectAsync, useMemoAsync } from '@chengsokdara/react-hooks-async';
import { useRef, useState, useEffect } from 'react';

var ie={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onDataAvailableTranscribe:void 0,onTranscribe:void 0},ce={stop:void 0},se={blob:void 0,text:void 0},le=O=>{let{apiKey:d$1,autoStart:v,autoTranscribe:A,mode:h,nonStop:x,removeSilence:B,stopTimeout:q,streaming:S,timeSlice:K,whisperConfig:u,onDataAvailable:$,onDataAvailableTranscribe:C,onTranscribe:U}={...ie,...O},p=useRef([]),i=useRef(),c$1=useRef(),n=useRef(),o=useRef(),m=useRef(ce),[j,T]=useState(!1),[z,W]=useState(!1),[N,b$1]=useState(!1),[G,f]=useState(se);useEffect(()=>()=>{p.current&&(p.current=[]),i.current&&(i.current.flush(),i.current=void 0),n.current&&(n.current.destroy(),n.current=void 0),w("stop"),c$1.current&&(c$1.current.off("speaking",k),c$1.current.off("stopped_speaking",R)),o.current&&(o.current.getTracks().forEach(e=>e.stop()),o.current=void 0);},[]),useEffectAsync(async()=>{v&&await F();},[v]);let J=async()=>{await F();},Q=async()=>{await Z();},V=async()=>{await E();},X=async()=>{p.current=[];},F=async()=>{try{if(o.current||await Y(),o.current){if(!n.current){let{default:{RecordRTCPromisesHandler:t,StereoAudioRecorder:r}}=await import('recordrtc'),a={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:r,sampleRate:44100,timeSlice:S?K:void 0,type:"audio",ondataavailable:A&&S?te:void 0};n.current=new t(o.current,a);}if(!i.current){let{Mp3Encoder:t}=await import('lamejs');i.current=new t(1,44100,96);}let e=await n.current.getState();(e==="inactive"||e==="stopped")&&await n.current.startRecording(),e==="paused"&&await n.current.resumeRecording(),x&&D("stop"),T(!0);}}catch{}},Y=async()=>{try{if(o.current&&o.current.getTracks().forEach(e=>e.stop()),o.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!c$1.current){let{default:e}=await import('hark');c$1.current=e(o.current,{interval:100,play:!1}),c$1.current.on("speaking",k),c$1.current.on("stopped_speaking",R);}}catch{}},D=e=>{m.current[e]||(m.current[e]=setTimeout(E,q));},k=()=>{W(!0),w("stop");},R=()=>{W(!1),x&&D("stop");},Z=async()=>{try{n.current&&(await n.current.getState()==="recording"&&await n.current.pauseRecording(),w("stop"),T(!1));}catch{}},E=async()=>{try{if(n.current){let e=await n.current.getState();if((e==="recording"||e==="paused")&&await n.current.stopRecording(),ee(),w("stop"),T(!1),A)await re();else {let t=await n.current.getBlob();f({blob:t});}await n.current.destroy(),p.current=[],i.current&&(i.current.flush(),i.current=void 0),n.current=void 0;}}catch{}},ee=()=>{c$1.current&&(c$1.current.off("speaking",k),c$1.current.off("stopped_speaking",R),c$1.current=void 0),o.current&&(o.current.getTracks().forEach(e=>e.stop()),o.current=void 0);},w=e=>{m.current[e]&&(clearTimeout(m.current[e]),m.current[e]=void 0);},H=async e=>{let{createFFmpeg:t}=await import('@ffmpeg/ffmpeg'),r=t({mainName:"main",corePath:b,log:!0});r.isLoaded()||await r.load();let a=await e.arrayBuffer();r.FS("writeFile","in.wav",new Uint8Array(a)),await r.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",c,"out.mp3");let s=await r.FS("readFile","out.mp3");if(s.length<=225)return r.exit(),f({blob:e}),b$1(!1),e;let g=new Blob([s.buffer],{type:"audio/mpeg"});return r.exit(),g||e},re=async()=>{try{if(i.current&&n.current&&await n.current.getState()==="stopped"){b$1(!0);let t=await n.current.getBlob();if(B)t=await H(t);else {let r=await t.arrayBuffer(),a=i.current.encodeBuffer(new Int16Array(r));t=new Blob([a],{type:"audio/mpeg"});}if(typeof U=="function"){let r=await U(t,p.current);f(r);}else if(d$1){let r=new File([t],"speech.mp3",{type:"audio/mpeg"}),a=await _(r);f({blob:t,text:a});}b$1(!1);}}catch{b$1(!1);}},te=async e=>{try{if(S&&n.current){if($?.(e),i.current){let r=await e.arrayBuffer(),a=i.current.encodeBuffer(new Int16Array(r)),s=new Blob([a],{type:"audio/mpeg"});p.current.push(s);}if(await n.current.getState()==="recording"){let r=new Blob(p.current,{type:"audio/mpeg"});B&&(r=await H(r));let a=new File([r],"speech.mp3",{type:"audio/mpeg"});if(typeof C=="function"){let s=await C(r,p.current);s&&f(g=>({...g,text:s.text}));}else if(d$1){let s=await _(a);s&&f(g=>({...g,text:s}));}}}}catch{}},_=useMemoAsync(async e=>{if(d$1){let t=new FormData;t.append("file",e),t.append("model","whisper-1"),h==="transcriptions"&&t.append("language",u?.language??"en"),u?.prompt&&t.append("prompt",u.prompt),u?.response_format&&t.append("response_format",u.response_format),u?.temperature&&t.append("temperature",`${u.temperature}`);let r={};r["Content-Type"]="multipart/form-data",r.Authorization=`Bearer ${d$1}`;let{default:a}=await import('axios');return (await a.post(d+h,t,{headers:r})).data.text}},[d$1,h,u]);return {recording:j,speaking:z,transcribing:N,transcript:G,pauseRecording:Q,startRecording:J,stopRecording:V,clearChunks:X}};

export { le as a };
