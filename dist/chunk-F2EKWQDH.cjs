'use strict';

var chunk57AVKP4H_cjs = require('./chunk-57AVKP4H.cjs');
var reactHooksAsync = require('@chengsokdara/react-hooks-async');
var react = require('react');

var oe={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onDataAvailableTranscribe:void 0,onTranscribe:void 0},ae={stop:void 0},ie={blob:void 0,text:void 0},pe=I=>{let{apiKey:d,autoStart:v,autoTranscribe:A,mode:h,nonStop:x,removeSilence:M,stopTimeout:O,streaming:S,timeSlice:q,whisperConfig:u,onDataAvailable:K,onDataAvailableTranscribe:C,onTranscribe:U}={...oe,...I},m=react.useRef([]),i=react.useRef(),c=react.useRef(),t=react.useRef(),a=react.useRef(),g=react.useRef(ae),[$,T]=react.useState(!1),[j,B]=react.useState(!1),[z,b]=react.useState(!1),[N,p]=react.useState(ie);react.useEffect(()=>()=>{m.current&&(m.current=[]),i.current&&(i.current.flush(),i.current=void 0),t.current&&(t.current.destroy(),t.current=void 0),w("stop"),c.current&&(c.current.off("speaking",k),c.current.off("stopped_speaking",R)),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},[]),reactHooksAsync.useEffectAsync(async()=>{v&&await W();},[v]);let G=async()=>{await W();},J=async()=>{await X();},Q=async()=>{await F();},W=async()=>{try{if(a.current||await V(),a.current){if(!t.current){let{default:{RecordRTCPromisesHandler:r,StereoAudioRecorder:o}}=await import('recordrtc'),n={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:o,sampleRate:44100,timeSlice:S?q:void 0,type:"audio",ondataavailable:A&&S?ee:void 0};t.current=new r(a.current,n);}if(!i.current){let{Mp3Encoder:r}=await import('lamejs');i.current=new r(1,44100,96);}let e=await t.current.getState();(e==="inactive"||e==="stopped")&&await t.current.startRecording(),e==="paused"&&await t.current.resumeRecording(),x&&D("stop"),T(!0);}}catch{}},V=async()=>{try{if(a.current&&a.current.getTracks().forEach(e=>e.stop()),a.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!c.current){let{default:e}=await import('hark');c.current=e(a.current,{interval:100,play:!1}),c.current.on("speaking",k),c.current.on("stopped_speaking",R);}}catch{}},D=e=>{g.current[e]||(g.current[e]=setTimeout(F,O));},k=()=>{B(!0),w("stop");},R=()=>{B(!1),x&&D("stop");},X=async()=>{try{t.current&&(await t.current.getState()==="recording"&&await t.current.pauseRecording(),w("stop"),T(!1));}catch{}},F=async()=>{try{if(t.current){let e=await t.current.getState();if((e==="recording"||e==="paused")&&await t.current.stopRecording(),Y(),w("stop"),T(!1),A)await Z();else {let r=await t.current.getBlob();p({blob:r});}await t.current.destroy(),m.current=[],i.current&&(i.current.flush(),i.current=void 0),t.current=void 0;}}catch{}},Y=()=>{c.current&&(c.current.off("speaking",k),c.current.off("stopped_speaking",R),c.current=void 0),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},w=e=>{g.current[e]&&(clearTimeout(g.current[e]),g.current[e]=void 0);},Z=async()=>{try{if(i.current&&t.current&&await t.current.getState()==="stopped"){b(!0);let r=await t.current.getBlob();if(M){let{createFFmpeg:o}=await import('@ffmpeg/ffmpeg'),n=o({mainName:"main",corePath:chunk57AVKP4H_cjs.b,log:!0});n.isLoaded()||await n.load();let s=await r.arrayBuffer();n.FS("writeFile","in.wav",new Uint8Array(s)),await n.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",chunk57AVKP4H_cjs.c,"out.mp3");let f=n.FS("readFile","out.mp3");if(f.length<=225){n.exit(),p({blob:r}),b(!1);return}r=new Blob([f.buffer],{type:"audio/mpeg"}),n.exit();}else {let o=await r.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o));r=new Blob([n],{type:"audio/mpeg"});}if(typeof U=="function"){let o=await U(r);p(o);}else if(d){let o=new File([r],"speech.mp3",{type:"audio/mpeg"}),n=await E(o);p({blob:r,text:n});}b(!1);}}catch{b(!1);}},ee=async e=>{try{if(S&&t.current){if(K?.(e),i.current){let o=await e.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o)),s=new Blob([n],{type:"audio/mpeg"});m.current.push(s);}if(await t.current.getState()==="recording"){let o=new Blob(m.current,{type:"audio/mpeg"}),n=new File([o],"speech.mp3",{type:"audio/mpeg"});if(typeof C=="function"){let s=await C(o);s&&p(f=>({...f,text:s.text}));}else if(d){let s=await E(n);s&&p(f=>({...f,text:s}));}}}}catch{}},E=reactHooksAsync.useMemoAsync(async e=>{if(d){let r=new FormData;r.append("file",e),r.append("model","whisper-1"),h==="transcriptions"&&r.append("language",u?.language??"en"),u?.prompt&&r.append("prompt",u.prompt),u?.response_format&&r.append("response_format",u.response_format),u?.temperature&&r.append("temperature",`${u.temperature}`);let o={};o["Content-Type"]="multipart/form-data",o.Authorization=`Bearer ${d}`;let{default:n}=await import('axios');return (await n.post(chunk57AVKP4H_cjs.d+h,r,{headers:o})).data.text}},[d,h,u]);return {recording:$,speaking:j,transcribing:z,transcript:N,pauseRecording:J,startRecording:G,stopRecording:Q}};

exports.a = pe;
