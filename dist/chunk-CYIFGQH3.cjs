'use strict';

require('./chunk-57AVKP4H.cjs');
var reactHooksAsync = require('@chengsokdara/react-hooks-async');
var react = require('react');

var F={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onDataAvailableTranscribe:void 0,onTranscribe:void 0},G={stop:void 0},J={blob:void 0,text:void 0},ie=A=>{let{apiKey:L,autoStart:b,autoTranscribe:C,mode:N,nonStop:S,removeSilence:Q,stopTimeout:U,streaming:p,timeSlice:W,whisperConfig:V,onDataAvailable:h,onDataAvailableTranscribe:X,onTranscribe:Y}={...F,...A},s=react.useRef([]),o=react.useRef(),n=react.useRef(),r=react.useRef(),t=react.useRef(),i=react.useRef(G),[D,d]=react.useState(!1),[E,y]=react.useState(!1),[H,Z]=react.useState(!1),[B,$]=react.useState(J);react.useEffect(()=>()=>{s.current&&(s.current=[]),o.current&&(o.current.flush(),o.current=void 0),r.current&&(r.current.destroy(),r.current=void 0),u("stop"),n.current&&(n.current.off("speaking",l),n.current.off("stopped_speaking",m)),t.current&&(t.current.getTracks().forEach(e=>e.stop()),t.current=void 0);},[]),reactHooksAsync.useEffectAsync(async()=>{b&&await k();},[b]);let x=async()=>{await k();},M=async()=>{await K();},P=async()=>{await R();},_=async()=>{s.current=[];},k=async()=>{try{if(t.current||await O(),t.current){if(!r.current){let{default:{RecordRTCPromisesHandler:a,StereoAudioRecorder:g}}=await import('recordrtc'),T={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:g,sampleRate:44100,timeSlice:p?W:void 0,type:"audio",ondataavailable:C&&p?q:void 0};r.current=new a(t.current,T);}if(!o.current){let{Mp3Encoder:a}=await import('lamejs');o.current=new a(1,44100,96);}let e=await r.current.getState();(e==="inactive"||e==="stopped")&&await r.current.startRecording(),e==="paused"&&await r.current.resumeRecording(),S&&w("stop"),d(!0);}}catch{}},O=async()=>{try{if(t.current&&t.current.getTracks().forEach(e=>e.stop()),t.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!n.current){let{default:e}=await import('hark');n.current=e(t.current,{interval:100,play:!1}),n.current.on("speaking",l),n.current.on("stopped_speaking",m);}}catch{}},w=e=>{i.current[e]||(i.current[e]=setTimeout(R,U));},l=()=>{y(!0),u("stop");},m=()=>{y(!1),S&&w("stop");},K=async()=>{try{r.current&&(await r.current.getState()==="recording"&&await r.current.pauseRecording(),u("stop"),d(!1));}catch{}},R=async()=>{try{if(r.current){let e=await r.current.getState();(e==="recording"||e==="paused")&&await r.current.stopRecording(),j(),u("stop"),d(!1),await r.current.destroy(),s.current=[],o.current&&(o.current.flush(),o.current=void 0),r.current=void 0;}}catch{}},j=()=>{n.current&&(n.current.off("speaking",l),n.current.off("stopped_speaking",m),n.current=void 0),t.current&&(t.current.getTracks().forEach(e=>e.stop()),t.current=void 0);},u=e=>{i.current[e]&&(clearTimeout(i.current[e]),i.current[e]=void 0);},q=async e=>{try{if(p&&r.current)if(o.current){let a=await e.arrayBuffer(),g=o.current.encodeBuffer(new Int16Array(a)),T=new Blob([g],{type:"audio/mpeg"});h?.(T);}else h?.(e);}catch{}};return {recording:D,speaking:E,transcribing:H,transcript:B,pauseRecording:M,startRecording:x,stopRecording:P,clearChunks:_}};

exports.a = ie;
